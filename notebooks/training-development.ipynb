{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6307ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/ocean/projects/asc170022p/mtragoza/lung-project/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c48df88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "WARNING: There was an error initializing an OpenFabrics device.\n",
      "\n",
      "  Local host:   dv004\n",
      "  Local device: mlx5_0\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "  var py_version = '3.4.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  var reloading = false;\n",
       "  var Bokeh = root.Bokeh;\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    if (!reloading) {\n",
       "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n",
       "      root._bokeh_is_loading = css_urls.length + 0;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    var existing_stylesheets = []\n",
       "    var links = document.getElementsByTagName('link')\n",
       "    for (var i = 0; i < links.length; i++) {\n",
       "      var link = links[i]\n",
       "      if (link.href != null) {\n",
       "\texisting_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
       "\ton_load()\n",
       "\tcontinue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    var existing_scripts = []\n",
       "    var scripts = document.getElementsByTagName('script')\n",
       "    for (var i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "\texisting_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      var url = js_exports[name];\n",
       "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.holoviz.org/panel/1.4.2/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var js_exports = {};\n",
       "  var css_urls = [];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "\ttry {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "\t} catch(e) {\n",
       "\t  if (!reloading) {\n",
       "\t    throw e;\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "\tvar NewBokeh = root.Bokeh;\n",
       "\tif (Bokeh.versions === undefined) {\n",
       "\t  Bokeh.versions = new Map();\n",
       "\t}\n",
       "\tif (NewBokeh.version !== Bokeh.version) {\n",
       "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "\t}\n",
       "\troot.Bokeh = Bokeh;\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "      if (!reloading && !bokeh_loaded) {\n",
       "\troot.Bokeh = undefined;\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "\trun_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.holoviz.org/panel/1.4.2/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1002'>\n",
       "  <div id=\"f8af81dd-43c7-487d-91f8-00f5f0e447d0\" data-root-id=\"p1002\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"eae51fa3-efa1-48ac-97e0-e4e7d250426c\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1002\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1003\",\"attributes\":{\"plot_id\":\"p1002\",\"comm_id\":\"58927c841e904675a874a1e8c183b52b\",\"client_comm_id\":\"1bbd1a038e2e483fa040cac4fdaeab01\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"eae51fa3-efa1-48ac-97e0-e4e7d250426c\",\"roots\":{\"p1002\":\"f8af81dd-43c7-487d-91f8-00f5f0e447d0\"},\"root_ids\":[\"p1002\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, os, pathlib, time\n",
    "os.environ['PKG_CONFIG_PATH'] = '/ocean/projects/asc170022p/mtragoza/mambaforge/envs/lung-project/lib/pkgconfig'\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import nibabel as nib\n",
    "import pygalmesh\n",
    "from mpi4py import MPI\n",
    "import fenics as fe\n",
    "import fenics_adjoint as fa\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_fenics\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('..')\n",
    "import project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad4aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "emory4dct = project.imaging.Emory4DCT('../data/Emory-4DCT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657ead31",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_radius = 20\n",
    "\n",
    "examples = []\n",
    "for case in emory4dct.cases:\n",
    "    for fixed_phase in emory4dct.phases:\n",
    "        moving_phase = (fixed_phase + 10) % 100\n",
    "        \n",
    "        anat_file = case.nifti_file(fixed_phase)\n",
    "        disp_file = case.disp_file(moving_phase, fixed_phase)\n",
    "        mask_file = case.mask_file(fixed_phase, roi='lung_combined_mask')\n",
    "        mesh_file = case.mesh_file(fixed_phase, radius=mesh_radius)\n",
    "        \n",
    "        example = (anat_file, disp_file, mask_file, mesh_file)\n",
    "        examples.append(example)\n",
    "        \n",
    "len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b84f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "     \n",
    "    def __init__(self, examples, dtype=torch.float32, device='cuda'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.examples = examples\n",
    "        self.dtype = dtype\n",
    "        self.device = device\n",
    "\n",
    "        self.cache = [None] * len(examples)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.cache[idx] is None:\n",
    "            self.cache[idx] = self.load_example(idx)\n",
    "        return self.cache[idx]\n",
    "    \n",
    "    def load_example(self, idx):\n",
    "        anat_file, disp_file, mask_file, mesh_file = self.examples[idx]    \n",
    "        example_name = anat_file.stem\n",
    "        \n",
    "        # load images from NIFTI files\n",
    "        anat = load_nii_file(anat_file)\n",
    "        disp = load_nii_file(disp_file)\n",
    "        mask = load_nii_file(mask_file)\n",
    "        \n",
    "        # load mesh from xdmf file\n",
    "        mesh = load_mesh_file(mesh_file)\n",
    "\n",
    "        # get image spatial resolution\n",
    "        resolution = anat.header.get_zooms()\n",
    "\n",
    "        # convert arrays to tensors with shape (c,x,y,z)\n",
    "        anat = torch.as_tensor(anat.get_fdata(), dtype=self.dtype, device=self.device).unsqueeze(0)\n",
    "        disp = torch.as_tensor(disp.get_fdata(), dtype=self.dtype, device=self.device).permute(3,0,1,2)\n",
    "        mask = torch.as_tensor(mask.get_fdata(), dtype=self.dtype, device=self.device).unsqueeze(0)\n",
    "\n",
    "        return anat, disp, mask, mesh, resolution, example_name\n",
    "    \n",
    "def load_nii_file(nii_file):\n",
    "    print(f'Loading {nii_file}... ', end='')\n",
    "    nifti = nib.load(nii_file)\n",
    "    print(nifti.header.get_data_shape())\n",
    "    return nifti\n",
    "\n",
    "def load_mesh_file(mesh_file):\n",
    "    print(f'Loading {mesh_file}... ', end='')\n",
    "    mesh = fe.Mesh()\n",
    "    with fe.XDMFFile(MPI.COMM_WORLD, str(mesh_file)) as f:\n",
    "        f.read(mesh)\n",
    "    print(mesh.num_vertices())\n",
    "    return mesh\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # we need a custom collate_fn bc mesh is not a tensor\n",
    "    anat = torch.stack([ex[0] for ex in batch])\n",
    "    mask = torch.stack([ex[1] for ex in batch])\n",
    "    disp = torch.stack([ex[2] for ex in batch])\n",
    "    resolution = [ex[3] for ex in batch]\n",
    "    mesh = [ex[4] for ex in batch]\n",
    "    name = [ex[5] for ex in batch]\n",
    "    return anat, mask, disp, resolution, mesh, name\n",
    "\n",
    "dataset = Dataset(examples, dtype=torch.float32, device='cuda')\n",
    "example = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292b5389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tensor_repr(t):\n",
    "    shape = tuple(t.shape)\n",
    "    is_nan = t.float().isnan()\n",
    "    not_nan = ~is_nan\n",
    "    num_nan = is_nan.sum()\n",
    "    mean = t[not_nan].mean()\n",
    "    std = t[not_nan].std() if not_nan.sum() > 1 else np.nan # hide the torch warning\n",
    "    return f'Tensor(shape={shape}, ={mean:.4f}, ={std:.4f}, #nan={num_nan}, dtype={t.dtype}, device={t.device})'\n",
    "\n",
    "torch.Tensor.__repr__ = my_tensor_repr\n",
    "\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464c2ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvUnit(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super().__init__()\n",
    "        self.norm = torch.nn.BatchNorm3d(in_channels)\n",
    "        self.conv = torch.nn.Conv3d(in_channels, out_channels, kernel_size, padding='same', padding_mode='replicate')\n",
    "        self.relu = torch.nn.LeakyReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvBlock(torch.nn.Sequential):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, num_conv_layers, hidden_channels=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if not hidden_channels:\n",
    "            hidden_channels = out_channels\n",
    "        elif num_conv_layers < 2:\n",
    "            print('Warning: hidden_channels argument only used if num_conv_layers >= 2')\n",
    "\n",
    "        for i in range(num_conv_layers):\n",
    "            layer = ConvUnit(\n",
    "                in_channels=(hidden_channels if i > 0 else in_channels),\n",
    "                out_channels=(hidden_channels if i < num_conv_layers - 1 else out_channels),\n",
    "                kernel_size=kernel_size\n",
    "            )\n",
    "            self.add_module(f'conv_unit{i}', layer)\n",
    "            \n",
    "\n",
    "class Upsample(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, mode):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'{type(self).__name__}(mode={self.mode})'\n",
    "        \n",
    "    def forward(self, x, size):\n",
    "        return F.interpolate(x, size=size, mode=self.mode)\n",
    "\n",
    "\n",
    "class EncoderBlock(torch.nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        conv_kernel_size,\n",
    "        num_conv_layers,\n",
    "        hidden_channels=None,\n",
    "        apply_pooling=True,\n",
    "        pool_kernel_size=2,\n",
    "        pool_type='max'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert pool_type in {'max', 'avg'}\n",
    "\n",
    "        if apply_pooling:\n",
    "            if pool_type == 'max':\n",
    "                self.pooling = torch.nn.MaxPool3d(kernel_size=pool_kernel_size)\n",
    "            elif pool_type == 'avg':\n",
    "                self.pooling = torch.nn.AvgPool3d(kernel_size=pool_kernel_size)\n",
    "        else:\n",
    "            self.pooling = None\n",
    "            \n",
    "        self.conv_block = ConvBlock(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=conv_kernel_size,\n",
    "            num_conv_layers=num_conv_layers,\n",
    "            hidden_channels=hidden_channels\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.pooling:\n",
    "            x = self.pooling(x)\n",
    "        x = self.conv_block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DecoderBlock(torch.nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        conv_kernel_size,\n",
    "        num_conv_layers,\n",
    "        hidden_channels=None,\n",
    "        upsample_mode='nearest'\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.upsample = Upsample(mode=upsample_mode)\n",
    "\n",
    "        self.conv_block = ConvBlock(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=conv_kernel_size,\n",
    "            num_conv_layers=num_conv_layers,\n",
    "            hidden_channels=hidden_channels,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, encoder_feats):\n",
    "        x = self.upsample(x, size=encoder_feats.shape[2:])\n",
    "        x = torch.cat([x, encoder_feats], dim=1)\n",
    "        x = self.conv_block(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7052d5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet3D(torch.nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        num_levels,\n",
    "        num_conv_layers,\n",
    "        conv_channels,\n",
    "        conv_kernel_size,\n",
    "        pool_kernel_size=2,\n",
    "        pool_type='max',\n",
    "        upsample_mode='trilinear',\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert num_levels > 0\n",
    "        \n",
    "        curr_channels = in_channels\n",
    "        next_channels = conv_channels\n",
    "        \n",
    "        self.encoder = torch.nn.Sequential()\n",
    "        for i in range(num_levels):\n",
    "        \n",
    "            encoder_block = EncoderBlock(\n",
    "                in_channels=curr_channels,\n",
    "                out_channels=next_channels,\n",
    "                conv_kernel_size=conv_kernel_size,\n",
    "                num_conv_layers=num_conv_layers,\n",
    "                apply_pooling=(i > 0),\n",
    "                pool_kernel_size=pool_kernel_size,\n",
    "                pool_type=pool_type\n",
    "            )\n",
    "            self.encoder.add_module(f'level{i}', encoder_block)\n",
    "\n",
    "            curr_channels = next_channels\n",
    "            next_channels = curr_channels * 2\n",
    "        \n",
    "        next_channels = curr_channels // 2\n",
    "        \n",
    "        self.decoder = torch.nn.Sequential()\n",
    "        for i in reversed(range(num_levels - 1)):\n",
    "\n",
    "            decoder_block = DecoderBlock(\n",
    "                in_channels=curr_channels + next_channels,\n",
    "                out_channels=next_channels,\n",
    "                conv_kernel_size=conv_kernel_size,\n",
    "                num_conv_layers=num_conv_layers,\n",
    "                upsample_mode=upsample_mode\n",
    "            )\n",
    "            self.decoder.add_module(f'level{i}', decoder_block)\n",
    "            \n",
    "            curr_channels = next_channels\n",
    "            next_channels = curr_channels // 2\n",
    "        \n",
    "        self.final_conv = torch.nn.Conv3d(curr_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # encoder part\n",
    "        encoder_feats = []\n",
    "        for i, encoder in enumerate(self.encoder):\n",
    "            x = encoder(x)\n",
    "            encoder_feats.append(x)\n",
    "        \n",
    "        # reverse encoder features to align with decoder\n",
    "        encoder_feats = encoder_feats[::-1]\n",
    "    \n",
    "        # decoder part\n",
    "        for i, decoder in enumerate(self.decoder):\n",
    "            x = decoder(x, encoder_feats[i+1])\n",
    "\n",
    "        return self.final_conv(x)\n",
    "\n",
    "\n",
    "model = UNet3D(in_channels=1, out_channels=1, num_levels=3, num_conv_layers=2, conv_channels=4, conv_kernel_size=3)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd0a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearElasticPDE(torch_fenics.FEniCSModule):\n",
    "    \n",
    "    def __init__(self, mesh):\n",
    "        super().__init__()\n",
    "        self.mesh = mesh\n",
    "        self.S = fe.FunctionSpace(mesh, 'P', 1)\n",
    "        self.V = fe.VectorFunctionSpace(mesh, 'P', 1)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'{type(self).__name__}({self.mesh})'\n",
    "        \n",
    "    def input_templates(self):\n",
    "        scalar_f = fa.Function(self.S)\n",
    "        vector_f = fa.Function(self.V)\n",
    "        return vector_f, scalar_f, scalar_f\n",
    "    \n",
    "    def solve(self, u_true, mu, rho):\n",
    "\n",
    "        # define physical parameters\n",
    "        g  = 9.8e-3 # gravitational acc (mm/s^2)\n",
    "        nu = 0.4    # Poisson's ratio (unitless)\n",
    "\n",
    "        # Lame's first parameter (Pa)\n",
    "        lam = 2*mu*nu/(1 - 2*nu)\n",
    "\n",
    "        # set displacement boundary condition\n",
    "        u_bc = fa.DirichletBC(self.V, u_true, 'on_boundary')\n",
    "\n",
    "        # body force and traction\n",
    "        #b = fe.as_vector([0, rho*g, 0])\n",
    "        b = fa.Constant([0, 0, 0])\n",
    "        t = fa.Constant([0, 0, 0])\n",
    "\n",
    "        # define stress and strain\n",
    "        def epsilon(u):\n",
    "            return (fe.grad(u) + fe.grad(u).T) / 2\n",
    "\n",
    "        def sigma(u):\n",
    "            I = fe.Identity(u.geometric_dimension())\n",
    "            return lam*fe.div(u)*I + 2*mu*epsilon(u)\n",
    "\n",
    "        # weak formulation\n",
    "        u = fe.TrialFunction(self.V)\n",
    "        v = fe.TestFunction(self.V)\n",
    "\n",
    "        a = fe.inner(sigma(u), epsilon(v)) * fe.dx\n",
    "        L = fe.dot(b, v)*fe.dx + fe.dot(t, v)*fe.dx\n",
    "\n",
    "        u_pred = fa.Function(self.V)\n",
    "        fa.solve(a == L, u_pred, u_bc)\n",
    "\n",
    "        return u_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f25e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_xarray(a, dims=None, coords=None, name=None):\n",
    "    if isinstance(a, torch.Tensor):\n",
    "        a = a.detach().cpu().numpy()\n",
    "    if dims is None:\n",
    "        dims = [f'dim{i}' for i in range(a.ndim)]\n",
    "    if coords is None:\n",
    "        coords = {d: np.arange(a.shape[i]) for i, d in enumerate(dims)}\n",
    "    return xr.DataArray(a, dims=dims, coords=coords, name=name)\n",
    "\n",
    "#project.visual.view(as_xarray(output_image[0], dims=['component', 'x', 'y', 'z']), cmap='seismic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dfce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "anat_image, u_true_image, mask, mesh, resolution, example_name = example\n",
    "print(example_name)\n",
    "print(anat_image)\n",
    "\n",
    "project.visual.view(as_xarray(anat_image, dims=['c', 'x', 'y', 'z'], name='CT')).update_index(c=0, z=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_pred_image = model.forward(anat_image.unsqueeze(0))[0]\n",
    "mu_pred_image = torch.nn.functional.softplus(mu_pred_image) * 1000\n",
    "print(mu_pred_image)\n",
    "\n",
    "project.visual.view(as_xarray(mu_pred_image * mask, dims=['c', 'x', 'y', 'z'], name='mu'), vmax=1e4).update_index(c=0, z=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eea7000",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_image = (1 + anat_image/1000) * 1000\n",
    "print(rho_image)\n",
    "\n",
    "project.visual.view(as_xarray(rho_image * mask, dims=['c', 'x', 'y', 'z']), cmap='Greys_r', vmin=0, vmax=1000).update_index(c=0, z=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876dd823",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.visual.view(as_xarray(u_true_image * mask, dims=['c', 'x', 'y', 'z'])).update_index(c=2, z=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac020fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "mu_pred_image = mu_pred_image.detach()\n",
    "mu_pred_image.requires_grad = True\n",
    "\n",
    "pde = LinearElasticPDE(mesh)\n",
    "\n",
    "u_true_dofs = project.interpolate.image_to_dofs(u_true_image, resolution, pde.V, radius=2*mesh_radius, sigma=mesh_radius/2).cpu()\n",
    "mu_pred_dofs = project.interpolate.image_to_dofs(mu_pred_image, resolution, pde.S, radius=2*mesh_radius, sigma=mesh_radius/2).cpu()\n",
    "rho_dofs = project.interpolate.image_to_dofs(rho_image, resolution, pde.S, radius=2*mesh_radius, sigma=mesh_radius/2).cpu()\n",
    "\n",
    "u_pred_dofs = pde.forward(\n",
    "    u_true_dofs.unsqueeze(0),\n",
    "    mu_pred_dofs.unsqueeze(0),\n",
    "    rho_dofs.unsqueeze(0),\n",
    ")[0]\n",
    "\n",
    "u_pred_dofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d197e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "u_pred_image = project.interpolate.dofs_to_image(u_pred_dofs, pde.V, u_true_image.shape[-3:], resolution)\n",
    "\n",
    "project.visual.view(as_xarray(u_pred_image * mask.cpu(), dims=['c', 'x', 'y', 'z'])).update_index(c=0, z=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74ad8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_norm(u):\n",
    "    u_norm2 = (u**2).sum(dim=-1)\n",
    "    return torch.mean(u_norm2)\n",
    "\n",
    "def compute_loss(u_pred, u_true, eps=1e-8):\n",
    "    u_diff = (u_pred - u_true)\n",
    "    u_diff_norm2 = (u_diff**2).sum(dim=-1)\n",
    "    u_true_norm2 = (u_true**2).sum(dim=-1) + eps\n",
    "    return torch.mean(u_diff_norm2 / u_true_norm2)\n",
    "\n",
    "L = compute_loss(u_pred_dofs, u_true_dofs)\n",
    "L.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32366577",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.visual.view(as_xarray(mu_pred_image.grad, dims=['channel', 'x', 'y', 'z'])).update_index(channel=0, z=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623459d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "\n",
    "    def __init__(self, model, dataset, batch_size, learning_rate):\n",
    "        self._model = model\n",
    "        self.train_loader = torch.utils.data.DataLoader(\n",
    "            dataset, batch_size, shuffle=True, collate_fn=collate_fn\n",
    "        )\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        self.epoch = 0\n",
    "        \n",
    "        index_cols = ['epoch', 'batch', 'example', 'phase']\n",
    "        self.metrics = pd.DataFrame(columns=index_cols)\n",
    "        self.metrics.set_index(index_cols, inplace=True)\n",
    "        \n",
    "        self.fig, self.ax = plt.subplots()\n",
    "        self.ax.set_ylabel('loss')\n",
    "        self.ax.set_xlabel('epoch')\n",
    "\n",
    "        self.artists = {}\n",
    "        self.artists['loss_mean'] = self.ax.plot([], [], label='loss')[0]\n",
    "        self.artists['loss_sem']  = self.ax.fill_between([], [], [], alpha=0.2)\n",
    "        \n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "    \n",
    "    @property\n",
    "    def dataset(self):\n",
    "        return self.train_loader.dataset\n",
    "        \n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        return self.train_loader.batch_sampler.batch_size\n",
    "    \n",
    "    @property\n",
    "    def learning_rate(self):\n",
    "        return self.optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    @property\n",
    "    def batches_per_epoch(self):\n",
    "        return int(np.ceil(len(self.dataset) / self.batch_size))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if self.epoch > 0:\n",
    "            loss = self.metrics.loc[self.epoch, 'loss'].mean()\n",
    "        else:\n",
    "            loss = None\n",
    "        return f'{type(self).__name__}(epoch={self.epoch}, loss={loss})'\n",
    "    \n",
    "    def update_plot(self):\n",
    "        m = self.metrics.reset_index()\n",
    "        \n",
    "        mean = m.groupby(['phase', 'epoch'])[['loss']].mean()\n",
    "        sem  = m.groupby(['phase', 'epoch'])[['loss']].sem()\n",
    "\n",
    "        train_mean = mean.loc['train'].reset_index()\n",
    "        train_sem  = sem.loc['train'].reset_index()\n",
    "        \n",
    "        self.artists['loss_mean'].set_xdata(train_mean.epoch)\n",
    "        self.artists['loss_mean'].set_ydata(train_mean.loss)\n",
    "        \n",
    "        loss_verts = np.concatenate([\n",
    "            np.stack([\n",
    "                train_mean.epoch,\n",
    "                train_mean.loss + train_sem.loss\n",
    "            ]).T,\n",
    "            np.stack([\n",
    "                train_mean.epoch,\n",
    "                train_mean.loss - train_sem.loss\n",
    "            ]).T[::-1]\n",
    "        ])\n",
    "        self.artists['loss_sem'].set_verts([loss_verts])\n",
    "        \n",
    "        self.ax.set_xlim(*estimate_limit(train_mean.epoch))\n",
    "        self.ax.set_ylim(*estimate_limit(loss_verts[:,1]))\n",
    "        self.fig.canvas.draw()\n",
    "        \n",
    "    def train(self, num_epochs):\n",
    "        \n",
    "        start_epoch = self.epoch\n",
    "        stop_epoch = self.epoch + num_epochs\n",
    "\n",
    "        print('Training...')\n",
    "        for i in range(start_epoch, stop_epoch):\n",
    "            print(f'Epoch {i+1}/{stop_epoch}')\n",
    "            \n",
    "            for j, batch in enumerate(self.train_loader):\n",
    "                anat_image, u_true_image, mask, mesh, resolution, example_name = batch\n",
    "\n",
    "                # predict elasticity from anatomical image\n",
    "                mu_pred_image = self.model.forward(anat_image)\n",
    "                mu_pred_image = torch.nn.functional.softplus(mu_pred_image) * 1000\n",
    "                rho_image = (1 + anat_image/1000) * 1000\n",
    "\n",
    "                # physical FEM simulation\n",
    "                loss = 0\n",
    "                for k in range(self.batch_size):          \n",
    "                    pde = LinearElasticPDE(mesh[k])\n",
    "\n",
    "                    # convert tensors to FEM basis coefficients\n",
    "                    u_true_dofs = project.interpolate.image_to_dofs(u_true_image[k], resolution[k], pde.V, radius=20, sigma=mesh_radius/2).cpu()\n",
    "                    mu_pred_dofs = project.interpolate.image_to_dofs(mu_pred_image[k], resolution[k], pde.S, radius=20, sigma=mesh_radius/2).cpu()\n",
    "                    rho_dofs = project.interpolate.image_to_dofs(rho_image[k], resolution[k], pde.S, radius=20, sigma=mesh_radius/2).cpu()\n",
    "    \n",
    "                    # solve FEM for simulated displacement coefficients\n",
    "                    u_pred_dofs = pde.forward(\n",
    "                        u_true_dofs.unsqueeze(0),\n",
    "                        mu_pred_dofs.unsqueeze(0),\n",
    "                        rho_dofs.unsqueeze(0),\n",
    "                    )[0]\n",
    "    \n",
    "                    # compare to true displacement coefficients\n",
    "                    loss_k = compute_loss(u_pred_dofs, u_true_dofs)\n",
    "                    loss += loss_k\n",
    "                \n",
    "                    # compute additional metrics\n",
    "                    key = (i+1, j+1, example_name[k], 'train')\n",
    "                    self.metrics.loc[key, 'loss'] = loss_k.item()\n",
    "                    self.metrics.loc[key, 'mu_pred_norm'] = compute_norm(mu_pred_dofs).item()\n",
    "                    self.metrics.loc[key, 'u_pred_norm'] = compute_norm(u_pred_dofs).item()\n",
    "                    self.metrics.loc[key, 'u_true_norm'] = compute_norm(u_true_dofs).item()\n",
    "            \n",
    "                loss /= self.batch_size\n",
    "                print(f'{example_name} loss = {loss:.4f}')\n",
    "                \n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                self.update_plot()\n",
    "            \n",
    "            self.epoch += 1\n",
    "    \n",
    "    def test(self, example):\n",
    "        anat_image, u_true_image, mask, mesh, resolution, example_name = example\n",
    "        \n",
    "        # predict elasticity from anatomical image\n",
    "        mu_pred_image = self.model.forward(anat_image.unsqueeze(0))[0]\n",
    "        mu_pred_image = torch.nn.functional.softplus(mu_pred_image) * 1000\n",
    "        rho_image = (1 + anat_image/1000) * 1000\n",
    "        \n",
    "        # physical FEM simulation\n",
    "        pde = LinearElasticPDE(mesh)\n",
    "        \n",
    "        # convert tensors to FEM basis coefficients\n",
    "        u_true_dofs = project.interpolate.image_to_dofs(u_true_image, resolution, pde.V, radius=20, sigma=mesh_radius/2).cpu()\n",
    "        mu_pred_dofs = project.interpolate.image_to_dofs(mu_pred_image, resolution, pde.S, radius=20, sigma=mesh_radius/2).cpu()\n",
    "        rho_dofs = project.interpolate.image_to_dofs(rho_image, resolution, pde.S, radius=20, sigma=mesh_radius/2).cpu()\n",
    "\n",
    "        # solve FEM for simulated displacement coefficients\n",
    "        u_pred_dofs = pde.forward(\n",
    "            u_true_dofs.unsqueeze(0),\n",
    "            mu_pred_dofs.unsqueeze(0),\n",
    "            rho_dofs.unsqueeze(0),\n",
    "        )[0]\n",
    "\n",
    "        # compare to true displacement coefficients\n",
    "        loss = compute_loss(u_pred_dofs, u_true_dofs)\n",
    "        \n",
    "        # convert simulated displacement field to image domain      \n",
    "        u_pred_image = project.interpolate.dofs_to_image(u_pred_dofs, pde.V, u_true_image.shape[-3:], resolution)\n",
    "        u_pred_image = torch.as_tensor(u_pred_image)\n",
    "        \n",
    "        return mu_pred_image, u_pred_image\n",
    "    \n",
    "\n",
    "def estimate_limit(x, pad=0.1):\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "    x_range = x_max - x_min\n",
    "    pad = pad * x_range\n",
    "    return x_min - pad/2, x_max + pad/2\n",
    "    \n",
    "\n",
    "trainer = Trainer(model, dataset, batch_size=4, learning_rate=1e-5)\n",
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a45670",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "trainer.train(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a36d013",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdf2153",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.metrics.groupby('epoch').mean().reset_index().plot(y='loss', x='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d94b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.metrics.groupby('epoch').mean().reset_index().plot(y='mu_pred_norm', x='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424e8696",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.metrics.groupby('epoch').mean().reset_index().plot(y='u_pred_norm', x='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc6548",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.metrics.groupby('epoch').mean().reset_index().plot(y='u_true_norm', x='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b15a7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "anat_image, u_true_image, mask, mesh, resolution, example_name = dataset[0]\n",
    "shape = tuple(anat_image.shape[1:])\n",
    "\n",
    "mu_pred_image, u_pred_image = trainer.test(dataset[0])\n",
    "mu_pred_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310ae459",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.visual.view(as_xarray(u_true_image * mask, dims=['c', 'x', 'y', 'z'], name='u'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c486c94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.visual.view(as_xarray(\n",
    "    u_pred_image * mask.cpu(),\n",
    "    dims=['c', 'x', 'y', 'z'],\n",
    "    coords={\n",
    "        'c': ['x', 'y', 'z'],\n",
    "        'x': np.arange(shape[0]) * resolution[0],\n",
    "        'y': np.arange(shape[1]) * resolution[1],\n",
    "        'z': np.arange(shape[2]) * resolution[2],\n",
    "    },\n",
    "    name='u'\n",
    "), y='z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33d4679",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "project.visual.view(as_xarray(\n",
    "    mu_pred_image * mask,\n",
    "    dims=['c', 'x', 'y', 'z'],\n",
    "    coords={\n",
    "        'c': [0],\n",
    "        'x': np.arange(shape[0]) * resolution[0],\n",
    "        'y': np.arange(shape[1]) * resolution[1],\n",
    "        'z': np.arange(shape[2]) * resolution[2],\n",
    "    },\n",
    "    name='mu'\n",
    "), y='z', vmax=1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f76e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_pred_image = mu_pred_image.detach()\n",
    "mu_pred_image.requires_grad = True\n",
    "mu_pred_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1096d500",
   "metadata": {},
   "outputs": [],
   "source": [
    "pde = LinearElasticPDE(mesh)\n",
    "\n",
    "mu_pred_dofs = project.interpolate.image_to_dofs(mu_pred_image, resolution, pde.S, radius=20, sigma=mesh_radius/2)\n",
    "mu_pred_dofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235b914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = mu_pred_dofs.sum()\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3562bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "L.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7809afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_pred_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8055be3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mu_interp_image = project.interpolate.dofs_to_image(mu_pred_dofs, pde.S, mu_pred_image.shape[-3:], resolution)\n",
    "mu_interp_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f277443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_interp_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e176ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.visual.view(as_xarray(\n",
    "    mu_interp_image,\n",
    "    dims=['x', 'y', 'z'],\n",
    "    coords={\n",
    "        'x': np.arange(shape[0]) * resolution[0],\n",
    "        'y': np.arange(shape[1]) * resolution[1],\n",
    "        'z': np.arange(shape[2]) * resolution[2],\n",
    "    },\n",
    "    name='mu'\n",
    "), y='z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abff0766",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.visual.view(as_xarray(\n",
    "    mu_pred_image.grad,\n",
    "    dims=['c', 'x', 'y', 'z'],\n",
    "    coords={\n",
    "        'c': [0],\n",
    "        'x': np.arange(shape[0]) * resolution[0],\n",
    "        'y': np.arange(shape[1]) * resolution[1],\n",
    "        'z': np.arange(shape[2]) * resolution[2],\n",
    "    }\n",
    "), y='z', cmap='seismic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4685a527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lung-project",
   "language": "python",
   "name": "lung-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
